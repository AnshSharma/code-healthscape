{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display, clear_output, Image\n",
    "from ipywidgets import *\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"analysis5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a8661684129f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print('pandas: {}'.format(pd.__version__))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print('ipywidgets: {}'.format(wg.__version__))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print('')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataframe loaded.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "# print('Python: {}'.format(sys.version))\n",
    "# print('pandas: {}'.format(pd.__version__))\n",
    "# print('ipywidgets: {}'.format(wg.__version__))\n",
    "# print('')\n",
    "print('Dataframe loaded.') \n",
    "\n",
    "import sys\n",
    "b = sys.getsizeof(df)\n",
    "\n",
    "print('Processed ' + str(len(df)) + ' entries in table.')\n",
    "\n",
    "import math\n",
    "def convert_size(size_bytes):\n",
    "   if size_bytes == 0:\n",
    "       return \"0B\"\n",
    "   size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "   i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "   p = math.pow(1024, i)\n",
    "   s = round(size_bytes / p, 2)\n",
    "   return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "print('Mem cache: ' + str(convert_size(b)))\n",
    "\n",
    "n = len(pd.unique(df['Project']))\n",
    "print('Number of projects in dataframe: ' + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 8,
        "width": 12
       }
      }
     }
    }
   },
   "source": [
    "# Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 15,
        "row": 11,
        "width": 12
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "s=wg.Dropdown(options=['-- waiting for input --', 'Beds', 'TotalBldg_GSF'], description='Search by: ')\n",
    "display(s)\n",
    "s1_opt = list(df['Cat_Major'].unique())\n",
    "s1_opt.insert(0, '-- waiting for input --')\n",
    "s1 = wg.Dropdown(options=s1_opt, description='Tab: ')\n",
    "s2 = wg.SelectMultiple(\n",
    "    rows=10,\n",
    "    description='Department: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def change_s1(*args):\n",
    "    df_temp = df.loc[df['Cat_Major'] == s1.value]\n",
    "    s2.options = df_temp['Cat_Minor'].unique()\n",
    "    \n",
    "s1.observe(change_s1, 'value')\n",
    "\n",
    "HBox([s1, s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s3 = wg.FloatText(\n",
    "    max='10000',\n",
    "    step='100',\n",
    "    description='Query: '\n",
    ")\n",
    "display(s3)\n",
    "\n",
    "s4 = wg.FloatLogSlider(\n",
    "    value=10,\n",
    "    base=10,\n",
    "    min=0, # max exponent of base\n",
    "    max=5, # min exponent of base\n",
    "    step=1, # exponent step\n",
    "    description='Deviation: ',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "\n",
    "display(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 15,
        "row": 26,
        "width": 7
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "out = wg.Output()\n",
    "display(out)\n",
    "\n",
    "def response(change):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        if s.value == 'Beds':\n",
    "            xT = 'Number of Beds'\n",
    "        else:\n",
    "            xT = 'Area'\n",
    "\n",
    "        df2 = df[s.value].value_counts()\n",
    "        df2 = df2.to_frame()\n",
    "        df3 = df2.reset_index()\n",
    "        # df3['index'].iplot(kind=\"histogram\", bins=20, title=\"Number of projects undertaken\", xTitle=xT, yTitle='Count', theme='white', color='blue')\n",
    "        figh = px.histogram(df3, x=\"index\", nbins=20, template='none', color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "                        labels={\n",
    "                             \"index\": xT\n",
    "                         },\n",
    "                        title=\"Number of projects undertaken till date\")\n",
    "        figh.show()\n",
    "        df_query = df.loc[(df[s.value] >= int(s3.value)-int(s4.value)) & (df[s.value] < int(s3.value)+int(s4.value))]\n",
    "        df4 = df_query.loc[(df['Cat_Minor'].isin(s2.value)) | (df['Cat_Minor'] == s2.value)]\n",
    "        # df4 = df.loc[df['Cat_Minor'].isin(s2.value) & df['Project'].isin(s3.value)]\n",
    "        # If you also want to filter out projects, this shows mean now\n",
    "        \n",
    "        \n",
    "        df5 = df4[['Cat_Minor', 'Total_SF']]\n",
    "        df6 = df5.groupby(['Cat_Minor'], as_index=False).mean()\n",
    "        df7 = df6.style.set_properties(**{'text-align': 'left'})\n",
    "        figp = px.pie(df6, values='Total_SF', names='Cat_Minor', title='Area Allocation (Mean)', hole=.5, color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "        figp.show()\n",
    "        \n",
    "        print('Mean Allocation: ')\n",
    "        display(df7)\n",
    "        \n",
    "        print('Queried dataframe: ')\n",
    "        df8 = df4[['Project', s.value]]\n",
    "        df9 = df8.groupby(['Project'], as_index=False).mean()\n",
    "        display(df9)\n",
    "        \n",
    "s.observe(response, names=\"value\")\n",
    "s2.observe(response, names=\"value\")\n",
    "s3.observe(response, names=\"value\")\n",
    "s4.observe(response, names=\"value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_image(*args):\n",
    "#     def f(x):\n",
    "#         display(Image('img/'+x))\n",
    "#     interact(f, x=list(df_path.loc[df_path['Path'].str.contains(a.value, flags=re.I, regex=True)]['Path'].unique()));\n",
    "\n",
    "# a.observe(show_image, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# # search_img = wg.Combobox(\n",
    "# #     placeholder='Choose Dept.',\n",
    "# #     options=list(df['Cat_Minor'].unique()),\n",
    "# #     description='Search:',\n",
    "# #     ensure_option=False,\n",
    "# #     disabled=False\n",
    "# # )\n",
    "\n",
    "# df_path = df[['Cat_Minor', 'Path']]\n",
    "# df_path = df_path.dropna()\n",
    "\n",
    "# # display(search_img)\n",
    "\n",
    "# @interact\n",
    "# def show_images(file=list(df_path.loc[df_path['Path'].str.contains(search_img.value, flags=re.I, regex=True)]['Path'].unique())):\n",
    "#     display(Image('img/'+file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "@interact\n",
    "def show_images(file=os.listdir('img/')):\n",
    "    display(Image('img/'+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# search_img = wg.Combobox(\n",
    "#     placeholder='Choose Dept.',\n",
    "#     options=list(df['Cat_Minor'].unique()),\n",
    "#     description='Search:',\n",
    "#     ensure_option=False,\n",
    "#     disabled=False\n",
    "# )\n",
    "\n",
    "# df_path = df[['Cat_Minor', 'Path']]\n",
    "# df_path = df_path.dropna()\n",
    "\n",
    "# display(search_img)\n",
    "\n",
    "\n",
    "# img_result = wg.Dropdown(options='')\n",
    "# display(img_result)\n",
    "\n",
    "\n",
    "# # Updates the image options based on directory value\n",
    "# def update_images(*args):\n",
    "#     df_imgq = df_path.loc[df_path['Path'].str.contains(search_img.value, flags=re.I, regex=True)]\n",
    "#     img_result.options = list(df_imgq['Path'].unique())\n",
    "\n",
    "# # Tie the image options to directory value\n",
    "# search_img.observe(update_images, 'value')\n",
    "\n",
    "# # Show image\n",
    "# def show_image(*args):\n",
    "#     display(Image(filename='img/' +img_result.value))\n",
    "# img_result.observe(show_image, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename='img/' +img_result.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = wg.Dropdown(options=['img', 'nature', 'assorted'])\n",
    "# images = wg.Dropdown(options=os.listdir(directory.value))\n",
    "# display(directory)\n",
    "# display(images)\n",
    "\n",
    "# # from IPython.display import Image\n",
    "# Image(filename=directory.value + '/' +images.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# print('sklearn: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_t1 = df.loc[(df['Cat_Major'] == 'D&T') & (df['Cat_Minor'] == 'Surgery')]\n",
    "# df_ml = df_t1[['Beds', 'TotalBldg_GSF', 'Total Net Area']].groupby(['Beds'], as_index=False).mean()\n",
    "# df_ml = df_ml.dropna()\n",
    "\n",
    "# df_ml.head()\n",
    "\n",
    "df_ml = df[['Beds', 'TotalBldg_GSF']].groupby(['Beds'], as_index=False).mean()\n",
    "df_ml = df_ml.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_ml.drop([\"TotalBldg_GSF\"], axis=1)\n",
    "y = df_ml[\"TotalBldg_GSF\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(X_train)\n",
    "test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbor (KNN) model for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(train_scaled, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mse = mean_squared_error(y_train, model.predict(train_scaled))\n",
    "mae = mean_absolute_error(y_train, model.predict(train_scaled))\n",
    "from math import sqrt\n",
    "print(\"mse = \",mse,\" & mae = \",mae,\" & rmse = \", sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = mean_squared_error(y_test, model.predict(test_scaled))\n",
    "test_mae = mean_absolute_error(y_test, model.predict(test_scaled))\n",
    "print(\"mse = \",test_mse,\" & mae = \",test_mae,\" & rmse = \", sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees & Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "tree_model = DecisionTreeRegressor()\n",
    "rf_model = RandomForestRegressor()\n",
    "tree_model.fit(train_scaled, y_train)\n",
    "rf_model.fit(train_scaled, y_train)\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "tree_mse = mean_squared_error(y_train, tree_model.predict(train_scaled))\n",
    "tree_mae = mean_absolute_error(y_train, tree_model.predict(train_scaled))\n",
    "rf_mse = mean_squared_error(y_train, rf_model.predict(train_scaled))\n",
    "rf_mae = mean_absolute_error(y_train, rf_model.predict(train_scaled))\n",
    "\n",
    "# from math import sqrt\n",
    "\n",
    "print(\"Decision Tree training mse = \",tree_mse,\" & mae = \",tree_mae,\" & rmse = \", sqrt(tree_mse))\n",
    "print(\"Random Forest training mse = \",rf_mse,\" & mae = \",rf_mae,\" & rmse = \", sqrt(rf_mse))\n",
    "\n",
    "tree_test_mse = mean_squared_error(y_test, tree_model.predict(test_scaled))\n",
    "tree_test_mae = mean_absolute_error(y_test, tree_model.predict(test_scaled))\n",
    "rf_test_mse = mean_squared_error(y_test, rf_model.predict(test_scaled))\n",
    "rf_test_mae = mean_absolute_error(y_test, rf_model.predict(test_scaled))\n",
    "\n",
    "print(\"Decision Tree test mse = \",tree_test_mse,\" & mae = \",tree_test_mae,\" & rmse = \", sqrt(tree_test_mse))\n",
    "print(\"Random Forest test mse = \",rf_test_mse,\" & mae = \",rf_test_mae,\" & rmse = \", sqrt(rf_test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network: MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "modelnn = MLPRegressor()\n",
    "modelnn.fit(train_scaled, y_train)"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "default_view",
    "version": 1,
    "views": {
     "default_view": {
      "cellMargin": 10,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "active_view",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
